import pandas as pd
import numpy as np
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

df = pd.read_csv('vader_nifty_cleaned_filled.csv')
df = df.drop(columns=['date'])
df = df.dropna()
df['Date'] = pd.to_datetime(df['Date'], format='%d-%m-%Y')
df = df.sort_values('Date')

scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(df[['vader_score', 'NIFTY_50_Close']])

def create_sequences(data, seq_len=10):
    X, y = [], []
    for i in range(len(data) - seq_len):
        X.append(data[i:i+seq_len])
        y.append(data[i+seq_len, 1])
    return np.array(X), np.array(y)

SEQ_LEN = 10
X, y = create_sequences(scaled_data, SEQ_LEN)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

# Separate scaler for just price
scaler_price = MinMaxScaler()
price_scaled = scaler_price.fit_transform(df[['NIFTY_50_Close']])

model = Sequential([
    LSTM(64, activation='relu', input_shape=(SEQ_LEN, 2)),
    Dense(1)
])
model.compile(optimizer='adam', loss='mse')
model.fit(X_train, y_train, epochs=30, batch_size=16, validation_data=(X_test, y_test))

def predict_nifty_from_news(news_text, recent_df):
    analyzer = SentimentIntensityAnalyzer()
    vader_score_today = analyzer.polarity_scores(news_text)['compound']

    last_price = recent_df['NIFTY_50_Close'].iloc[-1]
    temp_df = recent_df.copy()
    temp_df.loc[len(temp_df)] = [vader_score_today, last_price]

    scaled_input = scaler.transform(temp_df[['vader_score', 'NIFTY_50_Close']])
    X_input = scaled_input.reshape((1, 10, 2))

    pred_scaled = model.predict(X_input)
    predicted_price = scaler_price.inverse_transform(pred_scaled)[0][0]
    return predicted_price

if __name__ == '__main__':
    user_news = input("\nðŸ“° Enter today's news: ")
    recent_data = df[['vader_score', 'NIFTY_50_Close']].iloc[-9:].copy()
    predicted = predict_nifty_from_news(user_news, recent_data)
    print(f"\nðŸ“ˆ Predicted NIFTY Closing Price for Tomorrow: â‚¹{predicted:.2f}")
import pickle

model.save("model.h5")

with open("scaler.pkl", "wb") as f:
    pickle.dump(scaler_price, f)

with open("full_scaler.pkl", "wb") as f:
    pickle.dump(scaler, f)

df[['vader_score', 'NIFTY_50_Close']].iloc[-9:].to_csv("data.csv", index=False)
